# Mulitilingual-Toxic-Comment-Classification
A BERT model to identify toxicity comments across multiple languages trained on TPUs

NOTE: The model is still in fintuning stage 

## Context

This repository contains the notebooks for the competition [Jigsaw Multilingual Toxic Comment Classification](https://www.kaggle.com/c/jigsaw-multilingual-toxic-comment-classification/overview) in kaggle.


## About the Competition

It only takes one toxic comment to sour an online discussion. The Conversation AI team, a research initiative founded by Jigsaw and Google, builds technology to protect voices in conversation. A main area of focus is machine learning models that can identify toxicity in online conversations, where toxicity is defined as anything rude, disrespectful or otherwise likely to make someone leave a discussion. If these toxic contributions can be identified, we could have a safer, more collaborative internet.

## Progress

The model was able to acheive a **0.9001 accuracy score** on the multilingual test.
